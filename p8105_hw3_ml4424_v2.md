p8105\_hw3\_ml4424
================
Maggie Li (ml4424)
10/9/2020

## Problem 1

``` r
library(p8105.datasets)
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.4.0     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(utils)
library(ggplot2)
library(patchwork)
library(ggridges)
library(lubridate)
```

    ## 
    ## Attaching package: 'lubridate'

    ## The following objects are masked from 'package:base':
    ## 
    ##     date, intersect, setdiff, union

``` r
data("instacart")

## more descriptives for illustrative examples
length(unique(instacart$product_id))
```

    ## [1] 39123

``` r
length(unique(instacart$user_id))
```

    ## [1] 131209

``` r
length(unique(instacart$department))
```

    ## [1] 21

**Description**: This dataset contains 1,384,617 observations that
represent a unique product from an Instacart order in 2017. These data
appear nested: these are products within orders within customers. There
are 15 total variables; key variables include identifying the order that
product came from, identifying the product, the order in which the item
was added to the cart, if the product was a reorder, identifying the
customer, order sequence number of the specific user, the day of week
the order was placed, the hour of week the order was placed, the days
that have passed since the last order by the customer, the name of the
product, identifying the aisle and department of the product and the
names of the aisle and department.

There are 131,209 users ordering 39,123 unique products from 21 unique
departments such as dairy, canned goods, produce, bulk, bakery,
household, etc.

``` r
## How many aisles are there?
length(unique(instacart$aisle_id))
```

    ## [1] 134

``` r
## which aisles are the most items ordered from?
instacart %>% 
  count(aisle, name = "n_obs") %>% 
  arrange(desc(n_obs)) %>% 
  slice_head()
```

    ## # A tibble: 1 x 2
    ##   aisle             n_obs
    ##   <chr>             <int>
    ## 1 fresh vegetables 150609

**Comment**: There are 134 unique aisles. The fresh vegetable aisle has
the most items ordered from it.

``` r
## Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered. Arrange aisles sensibly, and organize your plot so others can read it.

## aisles with more than 10,000 items. there are 39 unique aisles
select_aisles <- instacart %>% 
  count(aisle, name = "n_obs") %>% 
  filter(n_obs > 10000)

##check names of aisles
unique(select_aisles$aisle)
```

    ##  [1] "baby food formula"             "baking ingredients"           
    ##  [3] "bread"                         "butter"                       
    ##  [5] "candy chocolate"               "canned jarred vegetables"     
    ##  [7] "canned meals beans"            "cereal"                       
    ##  [9] "chips pretzels"                "crackers"                     
    ## [11] "cream"                         "dry pasta"                    
    ## [13] "eggs"                          "energy granola bars"          
    ## [15] "fresh dips tapenades"          "fresh fruits"                 
    ## [17] "fresh herbs"                   "fresh vegetables"             
    ## [19] "frozen meals"                  "frozen produce"               
    ## [21] "hot dogs bacon sausage"        "ice cream ice"                
    ## [23] "juice nectars"                 "lunch meat"                   
    ## [25] "milk"                          "nuts seeds dried fruit"       
    ## [27] "oils vinegars"                 "other creams cheeses"         
    ## [29] "packaged cheese"               "packaged produce"             
    ## [31] "packaged vegetables fruits"    "paper goods"                  
    ## [33] "refrigerated"                  "soft drinks"                  
    ## [35] "soup broth bouillon"           "soy lactosefree"              
    ## [37] "spreads"                       "water seltzer sparkling water"
    ## [39] "yogurt"

``` r
## plot select aisles
aisles_plot <- ggplot(select_aisles, 
                      aes(x=aisle, y = n_obs, fill = aisle)) +
  geom_bar(stat="identity") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(
    title = "Number of Items in Aisles with over 10,000 items",
    y = "Number of Items",
    caption = "Data from Instacart")

aisles_plot
```

![](p8105_hw3_ml4424_v2_files/figure-gfm/part%202-1.png)<!-- -->

**Comment**: The two most popular items by an order of magnitude than
the rest are fresh fruits and fresh vegetables. Packaged vegetable
fruits, packaged cheese, yogurt, water seltzer sparkling water follow
after in number of products sold. The mean number of items sold out of
all these categories is 27,281 items and the median number is 16,201
items. Most categories had fewer than 25,000 total items sold within
them.

``` r
## Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”. Include the number of times each item is ordered in your table.

## baking ingredients
baking_top3 <- instacart %>% 
  filter(aisle == "baking ingredients") %>% 
  count(product_name, name = "n_obs") %>% 
  arrange(desc(n_obs)) %>% 
  head(3) %>% #select top 3
  mutate(aisle = "baking ingredients") #ID col once joined to other tbls
baking_top3
```

    ## # A tibble: 3 x 3
    ##   product_name      n_obs aisle             
    ##   <chr>             <int> <chr>             
    ## 1 Light Brown Sugar   499 baking ingredients
    ## 2 Pure Baking Soda    387 baking ingredients
    ## 3 Cane Sugar          336 baking ingredients

``` r
## dog food care
dogfood_top3 <- instacart %>% 
  filter(aisle == "dog food care") %>% 
  count(product_name, name = "n_obs") %>% 
  arrange(desc(n_obs)) %>% 
  head(3) %>% #select top 3
  mutate(aisle = "dog food care") #ID col once joined to other tbls
dogfood_top3
```

    ## # A tibble: 3 x 3
    ##   product_name                                  n_obs aisle        
    ##   <chr>                                         <int> <chr>        
    ## 1 Snack Sticks Chicken & Rice Recipe Dog Treats    30 dog food care
    ## 2 Organix Chicken & Brown Rice Recipe              28 dog food care
    ## 3 Small Dog Biscuits                               26 dog food care

``` r
## packaged vegetables fruits
pckgd_top3 <- instacart %>% 
  filter(aisle == "packaged vegetables fruits") %>% 
  count(product_name, name = "n_obs") %>% 
  arrange(desc(n_obs)) %>% 
  head(3) %>% #select top 3
  mutate(aisle = "packaged vegetables fruits") #ID col once joined to other tbls

pckgd_top3
```

    ## # A tibble: 3 x 3
    ##   product_name         n_obs aisle                     
    ##   <chr>                <int> <chr>                     
    ## 1 Organic Baby Spinach  9784 packaged vegetables fruits
    ## 2 Organic Raspberries   5546 packaged vegetables fruits
    ## 3 Organic Blueberries   4966 packaged vegetables fruits

``` r
##join these to make a single table
top3 <- rbind(baking_top3, dogfood_top3, pckgd_top3) %>%
  rename(num_times_ordered = n_obs)
top3
```

    ## # A tibble: 9 x 3
    ##   product_name                           num_times_ordered aisle                
    ##   <chr>                                              <int> <chr>                
    ## 1 Light Brown Sugar                                    499 baking ingredients   
    ## 2 Pure Baking Soda                                     387 baking ingredients   
    ## 3 Cane Sugar                                           336 baking ingredients   
    ## 4 Snack Sticks Chicken & Rice Recipe Do…                30 dog food care        
    ## 5 Organix Chicken & Brown Rice Recipe                   28 dog food care        
    ## 6 Small Dog Biscuits                                    26 dog food care        
    ## 7 Organic Baby Spinach                                9784 packaged vegetables …
    ## 8 Organic Raspberries                                 5546 packaged vegetables …
    ## 9 Organic Blueberries                                 4966 packaged vegetables …

**Comment**: Light brown sugar, pure baking soda, and cane sugar were
all the top items sold in baking ingredients, with 300-500 total orders
containing each. Snack Sticks Chicken & Rice Recipe Dog Treats, Organix
Chicken & Brown Rice Recipe, and small dog biscuits were the top items
sold in dog food care, with 26-30 total orders containing each. Organic
baby spinach, organic raspberries, and organic blueberries were the top
packaged vegetable fruit items sold, with 4900-9800 total orders
containing each.

``` r
# Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week; format this table for human readers (i.e. produce a 2 x 7 table).

## Note: each column is apple and coffee, each row is day of the week, each cell is mean hour of day they are ordered on each day of week 

pl_apples <- instacart %>% 
  filter(str_detect(product_name, 'Pink Lady Apples')) %>% 
  group_by(order_dow) %>% 
  summarize(mean_hr = mean(order_hour_of_day)) %>% 
  dplyr::rename(pink_lady_apples = mean_hr)
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
pl_apples
```

    ## # A tibble: 7 x 2
    ##   order_dow pink_lady_apples
    ##       <int>            <dbl>
    ## 1         0             13.2
    ## 2         1             11.4
    ## 3         2             12.1
    ## 4         3             14.0
    ## 5         4             12  
    ## 6         5             12.8
    ## 7         6             12.1

``` r
coffee_ic <- instacart %>% 
  filter(str_detect(product_name, 'Coffee Ice Cream')) %>% 
  group_by(order_dow) %>% 
  summarize(mean_hr = mean(order_hour_of_day)) %>% 
  dplyr::rename(coffee_ice_cream = mean_hr)
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
coffee_ic
```

    ## # A tibble: 7 x 2
    ##   order_dow coffee_ice_cream
    ##       <int>            <dbl>
    ## 1         0             13.5
    ## 2         1             13.7
    ## 3         2             15.3
    ## 4         3             15.3
    ## 5         4             14.8
    ## 6         5             12.2
    ## 7         6             13.9

``` r
mean_hrs_all <- inner_join(pl_apples, coffee_ic) %>% 
  mutate(order_dow = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", 
    "Friday", "Saturday"))
```

    ## Joining, by = "order_dow"

``` r
mean_hrs_all
```

    ## # A tibble: 7 x 3
    ##   order_dow pink_lady_apples coffee_ice_cream
    ##   <chr>                <dbl>            <dbl>
    ## 1 Sunday                13.2             13.5
    ## 2 Monday                11.4             13.7
    ## 3 Tuesday               12.1             15.3
    ## 4 Wednesday             14.0             15.3
    ## 5 Thursday              12               14.8
    ## 6 Friday                12.8             12.2
    ## 7 Saturday              12.1             13.9

**Comment**: On Sunday, pink lady apples and coffee ice cream were both
ordered on average a bit after at 1pm; on Monday, on average pink lady
apples were ordered a bit after 11am and coffee ice cream close to 2pm;
on Tuesday, on average pink lady apples were ordered around noon and
coffee ice cream a bit after 3pm; on Wednesday, on average pink lady
apples were ordered around 2pm and coffee ice cream a bit after 3pm; on
Thursday, on average pink lady apples were ordered at noon and coffee
ice cream a bit before 3pm; on Friday, on average pink lady apples were
ordered close to 1pm and coffee ice cream a bit after noon; on Saturday,
on average pink lady apples were ordered around noon and coffee ice
cream ordered at 2pm.

Sales were overall higher for coffee ice cream than pink lady apples
across all day sof the week. These patterns seem to fit with the trend
that ice cream tends to be more frequently ordered later in the day than
healthier snacks.

## Problem 2

``` r
## read and tidy
accel <- read_csv("prob2_data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  pivot_longer(cols = starts_with("activity"),
               names_to = "minute_of_day",
               values_to = "activity_ct") # onvert wide to long, each row is a minute of day
```

    ## 
    ## ── Column specification ──────────────────────────────────────────────────────────────
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )
    ## ℹ Use `spec()` for the full column specifications.

``` r
## add weekday vs weekend variable
accel <- accel %>% 
  mutate(weekday = ifelse(day %in% c('Monday','Tuesday',
                                     'Wednesday', 'Thursday',
                                     'Friday'),
                          "yes", "no")) 

## check that there are 1440 minutes in a 24-hour period
length(unique(accel$minute_of_day)) 
```

    ## [1] 1440

**Description**: The dataset contains a variable for week number (1-5),
day\_id to indicate study day (1-35) and day to indicate day of week,
minute of the day (1-1440), the activity counts for each minute, and
whether the activity count was recorded on a weekday or not. There are
50,400 data entries (7 days/week \* 5 weeks \* 1440 minutes/day).

``` r
## aggregate across minutes to create total activity count per day in table
daily_accel <- accel %>% 
  group_by(day_id) %>% 
  summarize(daily_ct = sum(activity_ct))
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
daily_accel
```

    ## # A tibble: 35 x 2
    ##    day_id daily_ct
    ##     <dbl>    <dbl>
    ##  1      1  480543.
    ##  2      2   78828.
    ##  3      3  376254 
    ##  4      4  631105 
    ##  5      5  355924.
    ##  6      6  307094.
    ##  7      7  340115.
    ##  8      8  568839 
    ##  9      9  295431 
    ## 10     10  607175 
    ## # … with 25 more rows

``` r
## plot it to spot any trends
ggplot(daily_accel, aes(x = day_id, y = daily_ct)) +
  geom_point()
```

![](p8105_hw3_ml4424_v2_files/figure-gfm/part%202%20aggregate%20and%20table-1.png)<!-- -->
**Trends**: There does not appear to be any trends present when we look
at aggregated daily activity count. The values fluctuate up and down
day-to-day across the study period. Most daily total activity counts are
around 400,000, but there are days that fluctuate substantially as well,
due to missing data, changes in activity during that day, or potentially
measurement error.

``` r
## order days of the week, convert minute to numeric for plot
accel <- accel %>% 
  mutate(day = factor(day, levels = c('Monday','Tuesday',
                                     'Wednesday', 'Thursday',
                                     'Friday', 'Saturday', 'Sunday'))) %>% 
  mutate(minute = as.numeric(str_extract(minute_of_day, "[^_]+$")))

## convert add hours column
accel_3 <- accel %>% 
  mutate(hour = minute %/% 60,
         hour = as.integer(hour),
         study_day = paste(week, day)) %>% 
  group_by(study_day, hour) %>% 
  summarize(mean_activity = mean(activity_ct))
```

    ## `summarise()` regrouping output by 'study_day' (override with `.groups` argument)

``` r
## add day of week identifier
accel_3_dow <- accel_3 %>% 
  mutate(dow = str_extract(study_day, "[^ ]+$"),
         dow = factor(dow, levels = c('Monday','Tuesday',
                                     'Wednesday', 'Thursday',
                                     'Friday', 'Saturday', 'Sunday'))) 
  
length(unique(accel$minute)) # check we still have 1440 min in 24-h day
```

    ## [1] 1440

``` r
## plot: should have 35 lines with 7 diff colors
accel_3_dow %>% ggplot(aes(x = hour,
                  y= mean_activity,
                  color = dow,
                  group = study_day)) +
  theme_linedraw() +
  # geom_point(aes(alpha = 0.5)) + ##cleaner without all the points
  geom_line() +
    labs(title = "Accelerometer Counts across 35 days",
       x = "Hour of Day",
       y = "Mean Hourly Activity Count") + # clean axis/titles
  scale_color_hue(name = "Study Day") # clean legend title
```

![](p8105_hw3_ml4424_v2_files/figure-gfm/part%203--%20plot%2024%20hr%20activity%20time%20by%20dow-1.png)<!-- -->
**Conclusions**: Consistently across all days of the week and study
period, the activity count values dip at the end of the day, near
midnight and stay low until rising again around 5am across all days of
the week. The average activity count during the 24-h period across all
study days appears to be around or a little below 500.

There appears to be differences in activity count throughout the day,
and also by day of the week. Values tend to be higher on weekends in the
late morning hours (10-11am) and afternoon (4-5pm). The weekday values
are more similar to one another, with slight peaks in the early morning
hours (6-7am) and a higher peak in the late evening around 8pm.

There also appears to be differences between given days of the week
across the five weeks; for example, the Sunday hourly activity counts
vary week-to-week, with some weeks having higher peaks (2 Sundays around
8am and 11am) or more normal (the rest of the Sundays during those
times) mean hourly activity counts.

## Problem 3

    ## # A tibble: 1 x 7
    ##      id  date   prcp   snow   snwd    tmax    tmin
    ##   <int> <int>  <int>  <int>  <int>   <int>   <int>
    ## 1     0     0 145838 381221 591786 1134358 1134420

    ## [1] 1222433

**Description**: The original data contain the ID of the weather
station, the date the data were collected, and the following five
metrics: precipitation level (1/10 mm), snowfall level (mm), snow depth
(mm), maximum temperature (1/10 degrees C), minimum temperature (1/10
degrees C). There are a total of 2,595,176 unique daily observations.
There is missing data for precipitation for 145838 observations, missing
data for snowfall for 381221 observations, missing data for snow depth
for 591786 observations, missing data for maximum temperature for
1134358 observations and missing data for minimum temperature for
1134420 observations.

A bit more than half the observations (1,222,433) contain at least one
missing metric out of the five.

``` r
## separate month date year; mutate precip to mm to be same as snow; tmax and tmin to degrees C instead of 10ths of degree
cleaned_ny_noaa <- ny_noaa %>% 
  separate(date, c("year", "month", "date")) %>% 
  mutate(prcp = prcp/10,
         tmax = as.integer(tmax)/10,
         tmin = as.integer(tmin)/10)
cleaned_ny_noaa
```

    ## # A tibble: 2,595,176 x 9
    ##    id          year  month date   prcp  snow  snwd  tmax  tmin
    ##    <chr>       <chr> <chr> <chr> <dbl> <int> <int> <dbl> <dbl>
    ##  1 US1NYAB0001 2007  11    01       NA    NA    NA    NA    NA
    ##  2 US1NYAB0001 2007  11    02       NA    NA    NA    NA    NA
    ##  3 US1NYAB0001 2007  11    03       NA    NA    NA    NA    NA
    ##  4 US1NYAB0001 2007  11    04       NA    NA    NA    NA    NA
    ##  5 US1NYAB0001 2007  11    05       NA    NA    NA    NA    NA
    ##  6 US1NYAB0001 2007  11    06       NA    NA    NA    NA    NA
    ##  7 US1NYAB0001 2007  11    07       NA    NA    NA    NA    NA
    ##  8 US1NYAB0001 2007  11    08       NA    NA    NA    NA    NA
    ##  9 US1NYAB0001 2007  11    09       NA    NA    NA    NA    NA
    ## 10 US1NYAB0001 2007  11    10       NA    NA    NA    NA    NA
    ## # … with 2,595,166 more rows

``` r
## drop weird values (negative snowfall)
cleaned_ny_noaa <- cleaned_ny_noaa %>% 
  filter(snow >= 0) 

## most commonly observed snowfall values
summary(cleaned_ny_noaa) # note that 1st quartile, median, and 3rd quartile snowfall are all 0mm
```

    ##       id                year              month               date          
    ##  Length:2213954     Length:2213954     Length:2213954     Length:2213954    
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##       prcp             snow                snwd             tmax       
    ##  Min.   :   0.0   Min.   :    0.000   Min.   :   0.0   Min.   :-38.9   
    ##  1st Qu.:   0.0   1st Qu.:    0.000   1st Qu.:   0.0   1st Qu.:  5.0   
    ##  Median :   0.0   Median :    0.000   Median :   0.0   Median : 15.6   
    ##  Mean   :   2.9   Mean   :    4.987   Mean   :  36.8   Mean   : 14.3   
    ##  3rd Qu.:   2.0   3rd Qu.:    0.000   3rd Qu.:   0.0   3rd Qu.: 23.9   
    ##  Max.   :2286.0   Max.   :10160.000   Max.   :9195.0   Max.   : 44.4   
    ##  NA's   :41988                        NA's   :227535   NA's   :925784  
    ##       tmin       
    ##  Min.   :-58.3   
    ##  1st Qu.: -3.3   
    ##  Median :  3.9   
    ##  Mean   :  3.2   
    ##  3rd Qu.: 11.7   
    ##  Max.   : 51.7   
    ##  NA's   :925908

``` r
nrow(cleaned_ny_noaa %>% filter(snow == 0))
```

    ## [1] 2008508

**Comments**: The most commonly observed value for snowfall is 0mm.
2,008,508 observations out of 2,213,954 total observations observed no
snowfall. This is to be expected, because in New York State, it
typically only snows a few months a year and there isn’t particularly
heavy snowfall across the state’s region.

``` r
## filter jan and july months
jan_jul_temps <- cleaned_ny_noaa %>% 
  filter(month == "01" | month == "07") %>% 
  select(id, year, month, date, tmax) %>% 
  drop_na()

## aggregate to get df of year, month (01 or 07), mean tmax; make year a double for plotting
jan_jul_temps
```

    ## # A tibble: 216,663 x 5
    ##    id          year  month date   tmax
    ##    <chr>       <chr> <chr> <chr> <dbl>
    ##  1 USC00300023 1981  01    01     -5.6
    ##  2 USC00300023 1981  01    02     -8.9
    ##  3 USC00300023 1981  01    03    -12.2
    ##  4 USC00300023 1981  01    04     -9.4
    ##  5 USC00300023 1981  01    05     -5.6
    ##  6 USC00300023 1981  01    11    -11.7
    ##  7 USC00300023 1981  01    12    -12.2
    ##  8 USC00300023 1981  01    13     -6.7
    ##  9 USC00300023 1981  01    14     -8.3
    ## 10 USC00300023 1981  01    15     -5  
    ## # … with 216,653 more rows

``` r
summary(jan_jul_temps)
```

    ##       id                year              month               date          
    ##  Length:216663      Length:216663      Length:216663      Length:216663     
    ##  Class :character   Class :character   Class :character   Class :character  
    ##  Mode  :character   Mode  :character   Mode  :character   Mode  :character  
    ##                                                                             
    ##                                                                             
    ##                                                                             
    ##       tmax       
    ##  Min.   :-31.70  
    ##  1st Qu.:  0.00  
    ##  Median : 19.40  
    ##  Mean   : 13.75  
    ##  3rd Qu.: 27.20  
    ##  Max.   : 44.40

``` r
jan_jul_mean_temps <- jan_jul_temps %>% 
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax)) %>% 
  mutate(year = as.numeric(year))
```

    ## `summarise()` regrouping output by 'id', 'year' (override with `.groups` argument)

``` r
jan_jul_mean_temps
```

    ## # A tibble: 7,253 x 4
    ## # Groups:   id, year [3,837]
    ##    id           year month mean_tmax
    ##    <chr>       <dbl> <chr>     <dbl>
    ##  1 USC00300023  1981 01        -3.17
    ##  2 USC00300023  1981 07        28.3 
    ##  3 USC00300023  1982 07        27.8 
    ##  4 USC00300023  1983 01         1.11
    ##  5 USC00300023  1983 07        29.8 
    ##  6 USC00300023  1984 07        27.2 
    ##  7 USC00300023  1985 01        -1.30
    ##  8 USC00300023  1989 07        27.1 
    ##  9 USC00300023  1990 01         4.92
    ## 10 USC00300023  1990 07        27.0 
    ## # … with 7,243 more rows

``` r
## plot
jan_jul_mean_temps %>% ggplot(aes(x=year, y = mean_tmax, color = month)) +
  geom_point(alpha = 0.5) + 
  geom_smooth() + 
  labs(title = "January and July Maximum Temperatures",
    y = "Year",
    x = "Maximum Temperature (C)",
    caption = "Data from NOAA") +
  facet_grid(~month) 
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

![](p8105_hw3_ml4424_v2_files/figure-gfm/part%202%20two%20panel%20plot%20of%20max%20jan%20july%20temps-1.png)<!-- -->
**Comments**: The mean maximum temperature for January is around 0
degrees C between 1981 and 2010. The mean maximum temperature for July
is around 25 degrees C between 1981 and 2010. Across the monitor
stations with available data, January maximum temperatures tend to
fluctuate more than July temperatures, which are more stable on average
across monitors stations year-to-year. In January, there appears to be
more outliers both in the positive and negative direction away from the
0 degrees C line, while outliers in July tend toward the negative
direction.

``` r
## plot annual averages of tmin and tmax to avoid plotting messy seasonal variations
annual_temps <- cleaned_ny_noaa %>%
  select(id, year, month, tmax, tmin) %>%
  drop_na() %>%
  group_by(year) %>%
  summarize(mean_tmax = mean(tmax),
            mean_tmin = mean(tmin)) %>%
  mutate(year = as.numeric(year))
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

``` r
## pivot into longer format (same as in lecture notes)
annual_temps_pivot <- annual_temps %>% 
  pivot_longer(mean_tmax:mean_tmin, 
               names_to = "observation", 
               values_to = "temp") 

annual_temp_plot <- ggplot() +
  geom_line(data = annual_temps_pivot,
            aes(x = year, y = temp, color = observation)) +
  labs(
    title = "Annual Mean Max and Min Temps",
    y = "Temperature (C)",
    x = "Year",
    caption = "Data from NOAA") + 
  scale_color_hue(name = "Type")
annual_temp_plot
```

![](p8105_hw3_ml4424_v2_files/figure-gfm/part%203.1%20showing%20tmax%20and%20tmin%20all%20months-1.png)<!-- -->

``` r
## filter accordingly
cleaned_snow <- cleaned_ny_noaa %>% 
  drop_na(snow) %>% 
  filter(snow > 0,
         snow < 100) %>% 
  group_by(year, month, id) %>% 
  summarize(agg_snow = mean(snow))
```

    ## `summarise()` regrouping output by 'year', 'month' (override with `.groups` argument)

``` r
cleaned_snow
```

    ## # A tibble: 30,652 x 4
    ## # Groups:   year, month [242]
    ##    year  month id          agg_snow
    ##    <chr> <chr> <chr>          <dbl>
    ##  1 1981  01    USC00300023     51  
    ##  2 1981  01    USC00300055     30.2
    ##  3 1981  01    USC00300085     24.8
    ##  4 1981  01    USC00300183     42.2
    ##  5 1981  01    USC00300220     38.9
    ##  6 1981  01    USC00300254     35.2
    ##  7 1981  01    USC00300331     18.9
    ##  8 1981  01    USC00300343     33.6
    ##  9 1981  01    USC00300379     42  
    ## 10 1981  01    USC00300424     34.2
    ## # … with 30,642 more rows

``` r
summary(cleaned_snow)
```

    ##      year              month                id               agg_snow    
    ##  Length:30652       Length:30652       Length:30652       Min.   : 3.00  
    ##  Class :character   Class :character   Class :character   1st Qu.:22.40  
    ##  Mode  :character   Mode  :character   Mode  :character   Median :30.83  
    ##                                                           Mean   :32.37  
    ##                                                           3rd Qu.:41.25  
    ##                                                           Max.   :99.00

``` r
# ## plot using ridges; note: not ideal
# ggplot(cleaned_snow, aes(x=agg_snow, y = year)) +
#   geom_density_ridges(scale = .85)

## plot using boxplots; note: more visually interpretable
snow_plot <- ggplot(cleaned_snow, aes(x=agg_snow, y = year)) +
  geom_boxplot() +
  labs(
    title = "Distribution of Snowfall by Year",
    y = "Year",
    x = "Snowfall (mm)",
    caption = "Data from NOAA")
```

``` r
annual_temp_plot + snow_plot
```

![](p8105_hw3_ml4424_v2_files/figure-gfm/part%203.3%20combine%20plots%20into%20same%20panel-1.png)<!-- -->
**Comments**: The annual mean maximum and minimum temperatures between
1981 and 2020 fluctuate considerably over time. That being said, the
time series for both max and min temperatures run pretty parallel to one
another (i.e. years of unusually high mean max temperatures also had
unusually high mean min temperatures; years of unusally low mean max
temperatures also had unusually low mean min temperatures). This plot
averages out the seasonal variability within years, so its
interpretation is most applicable to study questions that involve
examining variations in mean max and min temperatures year-to-year.

Some unsually high mean max/min temperature years include 1990, 1991,
1997, 2001, 2006. Some unusally low mean max/min temperature years
include 1989, 1994, 2000, 2003.

The distribution of snowfall greater than 0 mm and less than 100mm
between 1981 and 2010 remains pretty even across the entire period. The
median snowfall is around 30 mm and stays consistent year to year, give
or take a few mm. The upper and lower quartiles are also quite
consistent, with the 25th percentile around 22 mm and 75th percentile
around 40 mm.

Values greater than 75 mm were considered outliers for almost all study
years, except 1999 and 1994
